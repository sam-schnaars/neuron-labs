const volcengineTTS = require("../cloud-api/volcengine-tts");
const openaiTTS = require("../cloud-api/openai-tts");
const { chatWithLLM, chatWithLLMStream } = require("../cloud-api/openai-llm");
const { recognizeAudio } = require("../cloud-api/openai-asr");
const {
  recordAudio,
  playAudioData,
  createSteamResponser,
} = require("../device/audio");

const { display } = require("../device/display");
const { extractEmojis } = require("../utils");

const { partial, endPartial, getPlayEndPromise } = createSteamResponser(
  volcengineTTS,
  (sentences) => {
    const fullText = sentences.join("");
    display({
      status: "å›ç­”ä¸­",
      text: fullText,
      emoji: extractEmojis(fullText),
    });
  },
  (text) => {
    console.log("å®Œæ•´å›ç­”:", text);
  }
);

// main
(async () => {
  display();
  const filePath = "record.mp3";

  while (true) {
    console.log("è†å¬ä¸­...");
    display({ status: "æ­£åœ¨è†å¬", emoji: "ğŸ˜", text: "" });
    await recordAudio(filePath, 60);
    display({ status: "è¯†åˆ«ä¸­", emoji: "ğŸ¤”", text: "" });
    const text = await recognizeAudio(filePath);
    // const text = await volcengineASR(filePath);
    // è°ƒç”¨å­—èŠ‚è·³åŠ¨è¯­éŸ³åˆæˆï¼Œæ’­æŠ¥è¯†åˆ«ç»“æœ
    display({ text });
    if (text) {
      await Promise.all([
        chatWithLLMStream([{
          role: "user",
          content: text,
        }], partial, endPartial),
        getPlayEndPromise(),
      ]);
    } else {
      console.log("è¯†åˆ«ç»“æœä¸ºç©º, è¯·ç»§ç»­è¯´");
      display({ status: "è¯·ç»§ç»­è¯´" });
    }
  }
})();
